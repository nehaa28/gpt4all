{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVJeOKnvo/JTol+QAqW5By",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehaa28/gpt4all/blob/main/gpt4_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8uyEyYz2yYC",
        "outputId": "99b70e87-1c12-4077-d00f-b44e7b868be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gpt4all'...\n",
            "remote: Enumerating objects: 363, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 363 (delta 89), reused 43 (delta 39), pack-reused 232\u001b[K\n",
            "Receiving objects: 100% (363/363), 3.36 MiB | 27.52 MiB/s, done.\n",
            "Resolving deltas: 100% (190/190), done.\n",
            "Submodule 'peft' (https://github.com/huggingface/peft.git) registered for path 'peft'\n",
            "Submodule 'transformers' (https://github.com/huggingface/transformers.git) registered for path 'transformers'\n",
            "Cloning into '/content/gpt4all/peft'...\n",
            "remote: Enumerating objects: 1573, done.        \n",
            "remote: Counting objects: 100% (147/147), done.        \n",
            "remote: Compressing objects: 100% (88/88), done.        \n",
            "remote: Total 1573 (delta 62), reused 100 (delta 38), pack-reused 1426        \n",
            "Receiving objects: 100% (1573/1573), 4.40 MiB | 15.17 MiB/s, done.\n",
            "Resolving deltas: 100% (984/984), done.\n",
            "Cloning into '/content/gpt4all/transformers'...\n",
            "remote: Enumerating objects: 134547, done.        \n",
            "remote: Counting objects: 100% (116/116), done.        \n",
            "remote: Compressing objects: 100% (77/77), done.        \n",
            "remote: Total 134547 (delta 60), reused 78 (delta 38), pack-reused 134431        \n",
            "Receiving objects: 100% (134547/134547), 131.65 MiB | 14.39 MiB/s, done.\n",
            "Resolving deltas: 100% (101302/101302), done.\n",
            "Submodule path 'peft': checked out '098962fa6515f2e4fe83a757f5995d3ffbb1c373'\n",
            "Submodule path 'transformers': checked out 'cae78c46d658a8e496a815c2ee49b9b178fb9c9a'\n"
          ]
        }
      ],
      "source": [
        "!git clone --recurse-submodules https://github.com/nomic-ai/gpt4all.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git submodule configure && git submodule update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo10fn2_2zBD",
        "outputId": "73f18563-a214-45df-8dc6-4d03eed4989f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jnfas9Dp5P7r",
        "outputId": "317415c0-cc94-4297-dab2-b7324a2faa60"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd gpt4all/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVnkirwN5TNX",
        "outputId": "1e0ae0fe-19bf-4747-fd28-2a78443842bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt4all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60o1LtAu23zr",
        "outputId": "0715b769-a97d-4245-b579-48f4bf6e3135"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (22.0.4)\n",
            "Collecting peft\n",
            "  Downloading peft-0.2.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodelist-inflator\n",
            "  Downloading nodelist_inflator-0.2.0-py3-none-any.whl (2.7 kB)\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.8.3.tar.gz (765 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.4/765.4 KB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonlines\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 1)) (23.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 2)) (1.4.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 2)) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 2)) (2023.3.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 2)) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 2)) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 5)) (3.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 5)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 6)) (4.5.0)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 6)) (67.6.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 6)) (3.19.6)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 6)) (1.4.4)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.18.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 KB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 6)) (8.1.3)\n",
            "Collecting hjson\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-cpuinfo\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from deepspeed->-r requirements.txt (line 10)) (1.10.7)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from jsonlines->-r requirements.txt (line 12)) (22.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: deepspeed, pathtools\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.8.3-py3-none-any.whl size=776398 sha256=bedee24aea789945e923a699b3b0adb7a4b8c53643b789d6da89f4b8971030eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/ea/8f/0768328ba436ed66f602d8d3b809624448c9eb627434176d04\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=f0776e5243b8d4e960fb07ab1bb3bed4eeee573b1819b81e8e0b6aec218b6e1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built deepspeed pathtools\n",
            "Installing collected packages: tokenizers, sentencepiece, py-cpuinfo, pathtools, ninja, hjson, xxhash, smmap, setproctitle, sentry-sdk, nodelist-inflator, multidict, jsonlines, frozenlist, docker-pycreds, dill, async-timeout, yarl, torchmetrics, responses, multiprocess, huggingface-hub, gitdb, deepspeed, aiosignal, accelerate, transformers, GitPython, aiohttp, wandb, peft, datasets, evaluate\n",
            "Successfully installed GitPython-3.1.31 accelerate-0.18.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 deepspeed-0.8.3 dill-0.3.6 docker-pycreds-0.4.0 evaluate-0.4.0 frozenlist-1.3.3 gitdb-4.0.10 hjson-3.1.0 huggingface-hub-0.13.3 jsonlines-3.1.0 multidict-6.0.4 multiprocess-0.70.14 ninja-1.11.1 nodelist-inflator-0.2.0 pathtools-0.1.2 peft-0.2.0 py-cpuinfo-9.0.0 responses-0.18.0 sentencepiece-0.1.97 sentry-sdk-1.18.0 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.2 torchmetrics-0.11.4 transformers-4.27.3 wandb-0.14.0 xxhash-3.2.0 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h-KzfFEu5k4E",
        "outputId": "fa084e02-eeaa-4598-b660-7b3a58abfb73"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gpt4all'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPZPBVZL51Zd",
        "outputId": "509d9a1f-7d8a-446d-f94b-d897cf85afcc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mchat\u001b[0m/     \u001b[01;34meval_data\u001b[0m/             gpt4all-lora-demo.gif  TRAINING_LOG.md\n",
            "clean.py  eval_figures.py        \u001b[01;34mpeft\u001b[0m/                  train.py\n",
            "\u001b[01;34mconfigs\u001b[0m/  eval_self_instruct.py  README.md              \u001b[01;34mtransformers\u001b[0m/\n",
            "data.py   \u001b[01;34mfigs\u001b[0m/                  read.py\n",
            "env.yaml  generate.py            requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gpt4all/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dhnhvKs234l",
        "outputId": "f204c54d-f62c-4dec-a543-050b675d12bd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt4all/transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcZY-F6S6AsX",
        "outputId": "c575392a-0cc4-4982-92a1-ef2e7e5f5031"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/gpt4all/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (3.10.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (2022.12.7)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.28.0.dev0-0.editable-py3-none-any.whl size=35096 sha256=819a41739a3c70bada6889b81492e5847d9fdaa89fcec0fe360405ad9274d204\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jslzpuqh/wheels/91/e9/d1/15ebeeea5d5aeb45280cba198e08a918a4f62c82c1ee398853\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.27.3\n",
            "    Uninstalling transformers-4.27.3:\n",
            "      Successfully uninstalled transformers-4.27.3\n",
            "Successfully installed transformers-4.28.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yajmCoGq238H",
        "outputId": "12567ea0-90ff-47cc-ed19-bc8b6bea1a3a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt4all/peft\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na3Iy2_o6NWY",
        "outputId": "0589964f-2724-4d2f-c45a-200482099d2a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/gpt4all/peft\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (0.18.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (4.28.0.dev0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (5.9.4)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (1.13.1+cu116)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (3.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->peft==0.3.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->peft==0.3.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->peft==0.3.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->peft==0.3.0.dev0) (2.0.12)\n",
            "Building wheels for collected packages: peft\n",
            "  Building editable for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.3.0.dev0-0.editable-py3-none-any.whl size=12171 sha256=48e0699c60ed35bba7b093f1be52cfe2dbb508e0dfbb6656f4353acd7c8397f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c8zwml02/wheels/26/46/0e/c3bc989650ae9a8a26c7493f55bb7aed07c985e14047c09dad\n",
            "Successfully built peft\n",
            "Installing collected packages: peft\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.2.0\n",
            "    Uninstalling peft-0.2.0:\n",
            "      Successfully uninstalled peft-0.2.0\n",
            "Successfully installed peft-0.3.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch --dynamo_backend=inductor --num_processes=8 --num_machines=1 --machine_rank=0 --deepspeed_multinode_launcher standard --mixed_precision=bf16  --use_deepspeed --deepspeed_config_file=configs/deepspeed/ds_config.json train.py --config configs/train/finetune-7b.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spkI3wti6Prw",
        "outputId": "1e85c558-c33f-4f58-f067-d4159b357e62"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[10:28:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m                                                   \u001b]8;id=859547;file:///usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\u001b\\\u001b[2mrun.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=649294;file:///usr/local/lib/python3.9/dist-packages/torch/distributed/run.py#663\u001b\\\u001b[2m663\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m         *****************************************         \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         Setting OMP_NUM_THREADS environment variable for  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         each process to be \u001b[1;36m1\u001b[0m in default, to avoid your    \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         system being overloaded, please further tune the  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         variable for optimal performance in your          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         application as needed.                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         *****************************************         \u001b[2m          \u001b[0m\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "\u001b[2;36m[10:28:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m failed \u001b[1m(\u001b[0mexitcode: \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m local_rank: \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mpid: \u001b[1;36m4585\u001b[0m\u001b[1m)\u001b[0m of \u001b]8;id=801725;file:///usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=42391;file:///usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/api.py#673\u001b\\\u001b[2m673\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m         binary: \u001b[35m/usr/bin/\u001b[0m\u001b[95mpython3\u001b[0m                          \u001b[2m          \u001b[0m\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33maccelerate_cli.py\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m :\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m908\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mlaunch_command\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m905 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mp_from_config_flag:                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m906 \u001b[0m\u001b[2m│   │   │   \u001b[0margs.deepspeed_fields_from_accelerate_config.append(\u001b[33m\"\u001b[0m\u001b[33mmixed\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m907 \u001b[0m\u001b[2m│   │   \u001b[0margs.deepspeed_fields_from_accelerate_config = \u001b[33m\"\u001b[0m\u001b[33m,\u001b[0m\u001b[33m\"\u001b[0m.join(args.d \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m908 \u001b[2m│   │   \u001b[0mdeepspeed_launcher(args)                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m909 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_fsdp \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m910 \u001b[0m\u001b[2m│   │   \u001b[0mmulti_gpu_launcher(args)                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m911 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_megatron_lm \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m647\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mdeepspeed_launcher\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m644 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m645 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m patch_environment(**current_env):                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m646 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m647 \u001b[2m│   │   │   │   \u001b[0mdistrib_run.run(args)                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m648 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m649 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m is_rich_available() \u001b[95mand\u001b[0m debug:                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m650 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconsole = get_console()                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/distributed/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m753\u001b[0m in \u001b[92mrun\u001b[0m   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m750 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m751 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m752 \u001b[0m\u001b[2m│   \u001b[0mconfig, cmd, cmd_args = config_from_args(args)                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m753 \u001b[2m│   \u001b[0melastic_launch(                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m754 \u001b[0m\u001b[2m│   │   \u001b[0mconfig=config,                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m755 \u001b[0m\u001b[2m│   │   \u001b[0mentrypoint=cmd,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m756 \u001b[0m\u001b[2m│   \u001b[0m)(*cmd_args)                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m132\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m__call__\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._entrypoint = entrypoint                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m130 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, *args):                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m132 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m launch_agent(\u001b[96mself\u001b[0m._config, \u001b[96mself\u001b[0m._entrypoint, \u001b[96mlist\u001b[0m(args) \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_entrypoint_name\u001b[0m(                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m246\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92mlaunch_agent\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m243 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# if the error files for the failed children exist\u001b[0m         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m244 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# @record will copy the first error (root cause)\u001b[0m           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m245 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# to the error file of the launcher process.\u001b[0m               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m246 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m ChildFailedError(                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mname=entrypoint_name,                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfailures=result.failures,                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mChildFailedError: \u001b[0m\n",
            "============================================================\n",
            "train.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m:\n",
            "  time      : \u001b[1;36m2023\u001b[0m-\u001b[1;36m03\u001b[0m-29_\u001b[1;92m10:28:48\u001b[0m\n",
            "  host      : f37912c11601\n",
            "  rank      : \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mlocal_rank: \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
            "  exitcode  : \u001b[1;36m2\u001b[0m \u001b[1m(\u001b[0mpid: \u001b[1;36m4586\u001b[0m\u001b[1m)\u001b[0m\n",
            "  error_file: \u001b[1m<\u001b[0m\u001b[1;95mN\u001b[0m\u001b[39m/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4587\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m3\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4588\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m4\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4589\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4594\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m6\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4595\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m7\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4596\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[39m------------------------------------------------------------\u001b[0m\n",
            "\u001b[39mRoot Cause \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfirst observed failure\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4585\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A\u001b[0m\u001b[1m>\u001b[0m\n",
            "  traceback : To enable traceback see: \n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QKvEP1C36jWI",
        "outputId": "8ab2f6a3-8e21-4767-8f7b-0318cece92ea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gpt4all/peft'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints"
      ],
      "metadata": {
        "id": "8Vq1_OrO7RFk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WB-MXpS7Yq_",
        "outputId": "2413b758-ca12-4ea8-d7d7-000d21935840"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt4all/checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.amazonaws.com/static.nomic.ai/gpt4all/models/gpt4all-lora-quantized.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIOUlFcK7Yul",
        "outputId": "eab92de8-2bb6-44ac-d9c8-662f7537a23a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-29 10:33:12--  https://s3.amazonaws.com/static.nomic.ai/gpt4all/models/gpt4all-lora-quantized.bin\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.16.198, 52.217.94.102, 52.216.222.96, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.16.198|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4212732137 (3.9G) [application/octet-stream]\n",
            "Saving to: ‘gpt4all-lora-quantized.bin’\n",
            "\n",
            "gpt4all-lora-quanti 100%[===================>]   3.92G  38.2MB/s    in 95s     \n",
            "\n",
            "2023-03-29 10:34:48 (42.1 MB/s) - ‘gpt4all-lora-quantized.bin’ saved [4212732137/4212732137]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQSIZ0lY6lYv",
        "outputId": "df712432-5738-4f08-c452-e85bcc45ec9c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt4all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python generate.py --config configs/generate/generate.yaml --prompt \"Write a script to reverse a string in Python\""
      ],
      "metadata": {
        "id": "i6wyClsp6XWX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fnBueJUU7XBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/gpt4all/checkpoints/gpt4all-lora-quantized.bin /content/gpt4all/chat/"
      ],
      "metadata": {
        "id": "j9nPVfTG6c-Y"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8nuMxqfdIElz",
        "outputId": "b119a909-1f6c-4542-dd25-9bef9654c8cc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gpt4all'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYI7JyhZIQB2",
        "outputId": "03dd16bd-35a1-4f5e-af6c-d0b598b07034"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt4all/chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./gpt4all-lora-quantized-linux-x86"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buc0lrtHIRWj",
        "outputId": "f56d5089-b67c-4104-d62c-5dddd953a0d4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main: seed = 1680089381\n",
            "llama_model_load: loading model from 'gpt4all-lora-quantized.bin' - please wait ...\n",
            "llama_model_load: ggml ctx size = 6065.35 MB\n",
            "llama_model_load: memory_size =  2048.00 MB, n_mem = 65536\n",
            "llama_model_load: loading model part 1/1 from 'gpt4all-lora-quantized.bin'\n",
            "llama_model_load: .................................... done\n",
            "llama_model_load: model size =  4017.27 MB / num tensors = 291\n",
            "\n",
            "system_info: n_threads = 2 / 2 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n",
            "main: interactive mode on.\n",
            "sampling parameters: temp = 0.100000, top_k = 40, top_p = 0.950000, repeat_last_n = 64, repeat_penalty = 1.300000\n",
            "\n",
            "\n",
            "== Running in chat mode. ==\n",
            " - Press Ctrl+C to interject at any time.\n",
            " - Press Return to return control to LLaMA.\n",
            " - If you want to submit another line, end your input in '\\'.\n",
            "\u001b[33m\n",
            "> \u001b[1m\u001b[32mwhat is the date today?\n",
            "\u001b[0mThe current day and time are as follows (if applicable): Today, 12/30/2021 at [insert timezone]\u001b[0m\n",
            "> \u001b[1m\u001b[32mwho is prime minister of India?/\n",
            "\u001b[0mCurrently Narendra Modi serves as the Prime Minister. He was elected in May 2014 and has served since then. Previously, he also held this position from September to October 2017 when his predecessor resigned due to health reasons.\u001b[0m\n",
            "> \u001b[1m\u001b[32m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymSRBN7XIjhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GKAXW3DdIS-s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}