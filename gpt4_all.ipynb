{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNi8GZFFNScpVA5aOYdt2em",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehaa28/gpt4all/blob/main/gpt4_all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8uyEyYz2yYC",
        "outputId": "99b70e87-1c12-4077-d00f-b44e7b868be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gpt4all'...\n",
            "remote: Enumerating objects: 363, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 363 (delta 89), reused 43 (delta 39), pack-reused 232\u001b[K\n",
            "Receiving objects: 100% (363/363), 3.36 MiB | 27.52 MiB/s, done.\n",
            "Resolving deltas: 100% (190/190), done.\n",
            "Submodule 'peft' (https://github.com/huggingface/peft.git) registered for path 'peft'\n",
            "Submodule 'transformers' (https://github.com/huggingface/transformers.git) registered for path 'transformers'\n",
            "Cloning into '/content/gpt4all/peft'...\n",
            "remote: Enumerating objects: 1573, done.        \n",
            "remote: Counting objects: 100% (147/147), done.        \n",
            "remote: Compressing objects: 100% (88/88), done.        \n",
            "remote: Total 1573 (delta 62), reused 100 (delta 38), pack-reused 1426        \n",
            "Receiving objects: 100% (1573/1573), 4.40 MiB | 15.17 MiB/s, done.\n",
            "Resolving deltas: 100% (984/984), done.\n",
            "Cloning into '/content/gpt4all/transformers'...\n",
            "remote: Enumerating objects: 134547, done.        \n",
            "remote: Counting objects: 100% (116/116), done.        \n",
            "remote: Compressing objects: 100% (77/77), done.        \n",
            "remote: Total 134547 (delta 60), reused 78 (delta 38), pack-reused 134431        \n",
            "Receiving objects: 100% (134547/134547), 131.65 MiB | 14.39 MiB/s, done.\n",
            "Resolving deltas: 100% (101302/101302), done.\n",
            "Submodule path 'peft': checked out '098962fa6515f2e4fe83a757f5995d3ffbb1c373'\n",
            "Submodule path 'transformers': checked out 'cae78c46d658a8e496a815c2ee49b9b178fb9c9a'\n"
          ]
        }
      ],
      "source": [
        "!git clone --recurse-submodules https://github.com/nomic-ai/gpt4all.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git submodule configure && git submodule update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo10fn2_2zBD",
        "outputId": "73f18563-a214-45df-8dc6-4d03eed4989f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jnfas9Dp5P7r",
        "outputId": "317415c0-cc94-4297-dab2-b7324a2faa60"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd gpt4all/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVnkirwN5TNX",
        "outputId": "1e0ae0fe-19bf-4747-fd28-2a78443842bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt4all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60o1LtAu23zr",
        "outputId": "0715b769-a97d-4245-b579-48f4bf6e3135"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 KB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (22.0.4)\n",
            "Collecting peft\n",
            "  Downloading peft-0.2.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodelist-inflator\n",
            "  Downloading nodelist_inflator-0.2.0-py3-none-any.whl (2.7 kB)\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.8.3.tar.gz (765 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.4/765.4 KB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonlines\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 1)) (23.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 2)) (1.4.4)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 2)) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 2)) (2023.3.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 2)) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting huggingface-hub<1.0.0,>=0.2.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets->-r requirements.txt (line 2)) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 5)) (3.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->-r requirements.txt (line 5)) (2022.10.31)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 6)) (4.5.0)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 6)) (67.6.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 6)) (3.19.6)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 6)) (1.4.4)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.18.0-py2.py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 KB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb->-r requirements.txt (line 6)) (8.1.3)\n",
            "Collecting hjson\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-cpuinfo\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from deepspeed->-r requirements.txt (line 10)) (1.10.7)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from jsonlines->-r requirements.txt (line 12)) (22.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: deepspeed, pathtools\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.8.3-py3-none-any.whl size=776398 sha256=bedee24aea789945e923a699b3b0adb7a4b8c53643b789d6da89f4b8971030eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/ea/8f/0768328ba436ed66f602d8d3b809624448c9eb627434176d04\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=f0776e5243b8d4e960fb07ab1bb3bed4eeee573b1819b81e8e0b6aec218b6e1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built deepspeed pathtools\n",
            "Installing collected packages: tokenizers, sentencepiece, py-cpuinfo, pathtools, ninja, hjson, xxhash, smmap, setproctitle, sentry-sdk, nodelist-inflator, multidict, jsonlines, frozenlist, docker-pycreds, dill, async-timeout, yarl, torchmetrics, responses, multiprocess, huggingface-hub, gitdb, deepspeed, aiosignal, accelerate, transformers, GitPython, aiohttp, wandb, peft, datasets, evaluate\n",
            "Successfully installed GitPython-3.1.31 accelerate-0.18.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.10.1 deepspeed-0.8.3 dill-0.3.6 docker-pycreds-0.4.0 evaluate-0.4.0 frozenlist-1.3.3 gitdb-4.0.10 hjson-3.1.0 huggingface-hub-0.13.3 jsonlines-3.1.0 multidict-6.0.4 multiprocess-0.70.14 ninja-1.11.1 nodelist-inflator-0.2.0 pathtools-0.1.2 peft-0.2.0 py-cpuinfo-9.0.0 responses-0.18.0 sentencepiece-0.1.97 sentry-sdk-1.18.0 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.2 torchmetrics-0.11.4 transformers-4.27.3 wandb-0.14.0 xxhash-3.2.0 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h-KzfFEu5k4E",
        "outputId": "fa084e02-eeaa-4598-b660-7b3a58abfb73"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gpt4all'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPZPBVZL51Zd",
        "outputId": "509d9a1f-7d8a-446d-f94b-d897cf85afcc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mchat\u001b[0m/     \u001b[01;34meval_data\u001b[0m/             gpt4all-lora-demo.gif  TRAINING_LOG.md\n",
            "clean.py  eval_figures.py        \u001b[01;34mpeft\u001b[0m/                  train.py\n",
            "\u001b[01;34mconfigs\u001b[0m/  eval_self_instruct.py  README.md              \u001b[01;34mtransformers\u001b[0m/\n",
            "data.py   \u001b[01;34mfigs\u001b[0m/                  read.py\n",
            "env.yaml  generate.py            requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gpt4all/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dhnhvKs234l",
        "outputId": "f204c54d-f62c-4dec-a543-050b675d12bd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt4all/transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcZY-F6S6AsX",
        "outputId": "c575392a-0cc4-4982-92a1-ef2e7e5f5031"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/gpt4all/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (3.10.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.28.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.28.0.dev0) (2022.12.7)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.28.0.dev0-0.editable-py3-none-any.whl size=35096 sha256=819a41739a3c70bada6889b81492e5847d9fdaa89fcec0fe360405ad9274d204\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jslzpuqh/wheels/91/e9/d1/15ebeeea5d5aeb45280cba198e08a918a4f62c82c1ee398853\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.27.3\n",
            "    Uninstalling transformers-4.27.3:\n",
            "      Successfully uninstalled transformers-4.27.3\n",
            "Successfully installed transformers-4.28.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yajmCoGq238H",
        "outputId": "12567ea0-90ff-47cc-ed19-bc8b6bea1a3a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt4all/peft\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na3Iy2_o6NWY",
        "outputId": "0589964f-2724-4d2f-c45a-200482099d2a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/gpt4all/peft\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (0.18.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (4.28.0.dev0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (5.9.4)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (1.13.1+cu116)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from peft==0.3.0.dev0) (23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.13.0->peft==0.3.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (3.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers->peft==0.3.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->peft==0.3.0.dev0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->peft==0.3.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->peft==0.3.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers->peft==0.3.0.dev0) (2.0.12)\n",
            "Building wheels for collected packages: peft\n",
            "  Building editable for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.3.0.dev0-0.editable-py3-none-any.whl size=12171 sha256=48e0699c60ed35bba7b093f1be52cfe2dbb508e0dfbb6656f4353acd7c8397f5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c8zwml02/wheels/26/46/0e/c3bc989650ae9a8a26c7493f55bb7aed07c985e14047c09dad\n",
            "Successfully built peft\n",
            "Installing collected packages: peft\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.2.0\n",
            "    Uninstalling peft-0.2.0:\n",
            "      Successfully uninstalled peft-0.2.0\n",
            "Successfully installed peft-0.3.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch --dynamo_backend=inductor --num_processes=8 --num_machines=1 --machine_rank=0 --deepspeed_multinode_launcher standard --mixed_precision=bf16  --use_deepspeed --deepspeed_config_file=configs/deepspeed/ds_config.json train.py --config configs/train/finetune-7b.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spkI3wti6Prw",
        "outputId": "1e85c558-c33f-4f58-f067-d4159b357e62"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m[10:28:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m                                                   \u001b]8;id=859547;file:///usr/local/lib/python3.9/dist-packages/torch/distributed/run.py\u001b\\\u001b[2mrun.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=649294;file:///usr/local/lib/python3.9/dist-packages/torch/distributed/run.py#663\u001b\\\u001b[2m663\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m         *****************************************         \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         Setting OMP_NUM_THREADS environment variable for  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         each process to be \u001b[1;36m1\u001b[0m in default, to avoid your    \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         system being overloaded, please further tune the  \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         variable for optimal performance in your          \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         application as needed.                            \u001b[2m          \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m         *****************************************         \u001b[2m          \u001b[0m\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "/usr/bin/python3: can't open file '/content/gpt4all/peft/train.py': [Errno 2] No such file or directory\n",
            "\u001b[2;36m[10:28:48]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m failed \u001b[1m(\u001b[0mexitcode: \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m local_rank: \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mpid: \u001b[1;36m4585\u001b[0m\u001b[1m)\u001b[0m of \u001b]8;id=801725;file:///usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=42391;file:///usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/api.py#673\u001b\\\u001b[2m673\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m         binary: \u001b[35m/usr/bin/\u001b[0m\u001b[95mpython3\u001b[0m                          \u001b[2m          \u001b[0m\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33maccelerate_cli.py\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m :\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m908\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mlaunch_command\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m905 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mp_from_config_flag:                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m906 \u001b[0m\u001b[2m│   │   │   \u001b[0margs.deepspeed_fields_from_accelerate_config.append(\u001b[33m\"\u001b[0m\u001b[33mmixed\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m907 \u001b[0m\u001b[2m│   │   \u001b[0margs.deepspeed_fields_from_accelerate_config = \u001b[33m\"\u001b[0m\u001b[33m,\u001b[0m\u001b[33m\"\u001b[0m.join(args.d \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m908 \u001b[2m│   │   \u001b[0mdeepspeed_launcher(args)                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m909 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_fsdp \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m910 \u001b[0m\u001b[2m│   │   \u001b[0mmulti_gpu_launcher(args)                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m911 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_megatron_lm \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/accelerate/commands/\u001b[0m\u001b[1;33mlaunch.py\u001b[0m:\u001b[94m647\u001b[0m in  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mdeepspeed_launcher\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m644 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m645 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m patch_environment(**current_env):                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m646 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m647 \u001b[2m│   │   │   │   \u001b[0mdistrib_run.run(args)                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m648 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m649 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m is_rich_available() \u001b[95mand\u001b[0m debug:                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m650 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconsole = get_console()                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/distributed/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m753\u001b[0m in \u001b[92mrun\u001b[0m   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m750 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m751 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m752 \u001b[0m\u001b[2m│   \u001b[0mconfig, cmd, cmd_args = config_from_args(args)                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m753 \u001b[2m│   \u001b[0melastic_launch(                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m754 \u001b[0m\u001b[2m│   │   \u001b[0mconfig=config,                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m755 \u001b[0m\u001b[2m│   │   \u001b[0mentrypoint=cmd,                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m756 \u001b[0m\u001b[2m│   \u001b[0m)(*cmd_args)                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m132\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92m__call__\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._entrypoint = entrypoint                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m130 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, *args):                                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m132 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m launch_agent(\u001b[96mself\u001b[0m._config, \u001b[96mself\u001b[0m._entrypoint, \u001b[96mlist\u001b[0m(args) \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m134 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_entrypoint_name\u001b[0m(                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/distributed/launcher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m246\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92mlaunch_agent\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m243 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# if the error files for the failed children exist\u001b[0m         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m244 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# @record will copy the first error (root cause)\u001b[0m           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m245 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# to the error file of the launcher process.\u001b[0m               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m246 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m ChildFailedError(                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mname=entrypoint_name,                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfailures=result.failures,                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mChildFailedError: \u001b[0m\n",
            "============================================================\n",
            "train.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m:\n",
            "  time      : \u001b[1;36m2023\u001b[0m-\u001b[1;36m03\u001b[0m-29_\u001b[1;92m10:28:48\u001b[0m\n",
            "  host      : f37912c11601\n",
            "  rank      : \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mlocal_rank: \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
            "  exitcode  : \u001b[1;36m2\u001b[0m \u001b[1m(\u001b[0mpid: \u001b[1;36m4586\u001b[0m\u001b[1m)\u001b[0m\n",
            "  error_file: \u001b[1m<\u001b[0m\u001b[1;95mN\u001b[0m\u001b[39m/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4587\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m3\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4588\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m4\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4589\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m5\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4594\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m6\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4595\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m7\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4596\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A>\u001b[0m\n",
            "\u001b[39m  traceback : To enable traceback see: \u001b[0m\n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "\u001b[39m------------------------------------------------------------\u001b[0m\n",
            "\u001b[39mRoot Cause \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfirst observed failure\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[1;39m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
            "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m03\u001b[0m\u001b[39m-29_\u001b[0m\u001b[1;92m10:28:48\u001b[0m\n",
            "\u001b[39m  host      : f37912c11601\u001b[0m\n",
            "\u001b[39m  rank      : \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m2\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m4585\u001b[0m\u001b[1;39m)\u001b[0m\n",
            "\u001b[39m  error_file: <N/A\u001b[0m\u001b[1m>\u001b[0m\n",
            "  traceback : To enable traceback see: \n",
            "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QKvEP1C36jWI",
        "outputId": "8ab2f6a3-8e21-4767-8f7b-0318cece92ea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gpt4all/peft'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints"
      ],
      "metadata": {
        "id": "8Vq1_OrO7RFk"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WB-MXpS7Yq_",
        "outputId": "2413b758-ca12-4ea8-d7d7-000d21935840"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt4all/checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://s3.amazonaws.com/static.nomic.ai/gpt4all/models/gpt4all-lora-quantized.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIOUlFcK7Yul",
        "outputId": "eab92de8-2bb6-44ac-d9c8-662f7537a23a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-29 10:33:12--  https://s3.amazonaws.com/static.nomic.ai/gpt4all/models/gpt4all-lora-quantized.bin\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.16.198, 52.217.94.102, 52.216.222.96, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.16.198|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4212732137 (3.9G) [application/octet-stream]\n",
            "Saving to: ‘gpt4all-lora-quantized.bin’\n",
            "\n",
            "gpt4all-lora-quanti 100%[===================>]   3.92G  38.2MB/s    in 95s     \n",
            "\n",
            "2023-03-29 10:34:48 (42.1 MB/s) - ‘gpt4all-lora-quantized.bin’ saved [4212732137/4212732137]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQSIZ0lY6lYv",
        "outputId": "df712432-5738-4f08-c452-e85bcc45ec9c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt4all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --config configs/generate/generate.yaml --prompt \"Write a script to reverse a string in Python\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6wyClsp6XWX",
        "outputId": "236cf26a-e670-40db-ed72-669375cd5bb8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up model\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_errors.py\u001b[0m:\u001b[94m259\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92mhf_raise_for_status\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m256 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m</Tip>\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m257 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m258 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m259 \u001b[2m│   │   \u001b[0mresponse.raise_for_status()                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m HTTPError \u001b[94mas\u001b[0m e:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2m│   │   \u001b[0merror_code = response.headers.get(\u001b[33m\"\u001b[0m\u001b[33mX-Error-Code\u001b[0m\u001b[33m\"\u001b[0m)              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m262 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/requests/\u001b[0m\u001b[1;33mmodels.py\u001b[0m:\u001b[94m960\u001b[0m in             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mraise_for_status\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m957 \u001b[0m\u001b[2m│   │   │   \u001b[0mhttp_error_msg = \u001b[33mu\u001b[0m\u001b[33m'\u001b[0m\u001b[33m%s\u001b[0m\u001b[33m Server Error: \u001b[0m\u001b[33m%s\u001b[0m\u001b[33m for url: \u001b[0m\u001b[33m%s\u001b[0m\u001b[33m'\u001b[0m % (\u001b[96msel\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m958 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m959 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m http_error_msg:                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m960 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m HTTPError(http_error_msg, response=\u001b[96mself\u001b[0m)             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m961 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m962 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mclose\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m963 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Releases the connection back to the pool. Once this method \u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mHTTPError: \u001b[0m\u001b[1;36m401\u001b[0m Client Error: Unauthorized for url: \n",
            "\u001b[4;94mhttps://huggingface.co/LlamaForCausalLM/resolve/main/config.json\u001b[0m\n",
            "\n",
            "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
            "\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/gpt4all/transformers/src/transformers/utils/\u001b[0m\u001b[1;33mhub.py\u001b[0m:\u001b[94m409\u001b[0m in           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mcached_file\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 406 \u001b[0m\u001b[2m│   \u001b[0muser_agent = http_user_agent(user_agent)                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 407 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 408 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Load from URL or cache if already cached\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 409 \u001b[2m│   │   \u001b[0mresolved_file = hf_hub_download(                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 410 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_or_repo_id,                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 411 \u001b[0m\u001b[2m│   │   │   \u001b[0mfilename,                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 412 \u001b[0m\u001b[2m│   │   │   \u001b[0msubfolder=\u001b[94mNone\u001b[0m \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(subfolder) == \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m subfolder,     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m: \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[94m120\u001b[0m in \u001b[92m_inner_fn\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__na\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m120 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mfile_download.py\u001b[0m:\u001b[94m1160\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92mhf_hub_download\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1157 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m local_files_only:                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1158 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1159 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1160 \u001b[2m│   │   │   │   \u001b[0mmetadata = get_hf_file_metadata(                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1161 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0murl=url,                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1162 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mtoken=token,                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1163 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mproxies=proxies,                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m: \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[94m120\u001b[0m in \u001b[92m_inner_fn\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m check_use_auth_token:                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[91m__na\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m120 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _inner_fn  \u001b[2m# type: ignore\u001b[0m                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/huggingface_hub/\u001b[0m\u001b[1;33mfile_download.py\u001b[0m:\u001b[94m1501\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92mget_hf_file_metadata\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0mproxies=proxies,                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   \u001b[0mtimeout=timeout,                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   \u001b[0m)                                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   \u001b[0mhf_raise_for_status(r)                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Return\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m HfFileMetadata(                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_errors.py\u001b[0m:\u001b[94m291\u001b[0m  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m in \u001b[92mhf_raise_for_status\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m288 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m `repo_type`.\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33mIf you are trying to access a private \u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m289 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m make sure you are authenticated.\u001b[0m\u001b[33m\"\u001b[0m                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m290 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m291 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m RepositoryNotFoundError(message, response) \u001b[94mfrom\u001b[0m \u001b[4;96me\u001b[0m    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m292 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m response.status_code == \u001b[94m400\u001b[0m:                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[2m│   │   │   \u001b[0mmessage = (                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mRepositoryNotFoundError: \u001b[0m\u001b[1;36m401\u001b[0m Client Error. \u001b[1m(\u001b[0mRequest ID: \n",
            "\u001b[33mRoot\u001b[0m=\u001b[1;36m1\u001b[0m-64241d98-6169be9749eab34f73cb572c\u001b[1m)\u001b[0m\n",
            "\n",
            "Repository Not Found for url: \n",
            "\u001b[4;94mhttps://huggingface.co/LlamaForCausalLM/resolve/main/config.json.\u001b[0m\n",
            "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
            "If you are trying to access a private or gated repo, make sure you are \n",
            "authenticated.\n",
            "Invalid username or password.\n",
            "\n",
            "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
            "\n",
            "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/gpt4all/\u001b[0m\u001b[1;33mgenerate.py\u001b[0m:\u001b[94m52\u001b[0m in \u001b[92m<module>\u001b[0m                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m49 \u001b[0m\u001b[2m│   \u001b[0mprompt = config[\u001b[33m\"\u001b[0m\u001b[33mprompt\u001b[0m\u001b[33m\"\u001b[0m] \u001b[94mif\u001b[0m args.prompt \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m args.prompt   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mSetting up model\u001b[0m\u001b[33m\"\u001b[0m)                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m52 \u001b[2m│   \u001b[0mmodel, tokenizer = setup_model(config)                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m54 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mGenerating\u001b[0m\u001b[33m\"\u001b[0m)                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m55 \u001b[0m\u001b[2m│   \u001b[0mstart = time.time()                                                 \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/gpt4all/\u001b[0m\u001b[1;33mgenerate.py\u001b[0m:\u001b[94m20\u001b[0m in \u001b[92msetup_model\u001b[0m                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92msetup_model\u001b[0m(config):                                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m20 \u001b[2m│   \u001b[0mmodel = AutoModelForCausalLM.from_pretrained(config[\u001b[33m\"\u001b[0m\u001b[33mmodel_name\u001b[0m\u001b[33m\"\u001b[0m],  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m\u001b[2m│   \u001b[0mtokenizer = AutoTokenizer.from_pretrained(config[\u001b[33m\"\u001b[0m\u001b[33mtokenizer_name\u001b[0m\u001b[33m\"\u001b[0m]) \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2m│   \u001b[0madded_tokens = tokenizer.add_special_tokens({\u001b[33m\"\u001b[0m\u001b[33mbos_token\u001b[0m\u001b[33m\"\u001b[0m: \u001b[33m\"\u001b[0m\u001b[33m<s>\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33me\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m23 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/gpt4all/transformers/src/transformers/models/auto/\u001b[0m\u001b[1;33mauto_factory.py\u001b[0m:\u001b[94m4\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[94m41\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m438 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m kwargs_copy.get(\u001b[33m\"\u001b[0m\u001b[33mtorch_dtype\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mNone\u001b[0m) == \u001b[33m\"\u001b[0m\u001b[33mauto\u001b[0m\u001b[33m\"\u001b[0m:         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m439 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m_ = kwargs_copy.pop(\u001b[33m\"\u001b[0m\u001b[33mtorch_dtype\u001b[0m\u001b[33m\"\u001b[0m)                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m440 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m441 \u001b[2m│   │   │   \u001b[0mconfig, kwargs = AutoConfig.from_pretrained(               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m442 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mpretrained_model_name_or_path,                         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m443 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mreturn_unused_kwargs=\u001b[94mTrue\u001b[0m,                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m444 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtrust_remote_code=trust_remote_code,                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/gpt4all/transformers/src/transformers/models/auto/\u001b[0m\u001b[1;33mconfiguration_aut\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[1;33mo.py\u001b[0m:\u001b[94m905\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m902 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33m_from_auto\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[94mTrue\u001b[0m                                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m903 \u001b[0m\u001b[2m│   │   \u001b[0mkwargs[\u001b[33m\"\u001b[0m\u001b[33mname_or_path\u001b[0m\u001b[33m\"\u001b[0m] = pretrained_model_name_or_path         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m904 \u001b[0m\u001b[2m│   │   \u001b[0mtrust_remote_code = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mtrust_remote_code\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mFalse\u001b[0m)     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m905 \u001b[2m│   │   \u001b[0mconfig_dict, unused_kwargs = PretrainedConfig.get_config_dict( \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m906 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mauto_map\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mAutoConfig\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict[\u001b[33m\"\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m907 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m trust_remote_code:                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m908 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                      \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/gpt4all/transformers/src/transformers/\u001b[0m\u001b[1;33mconfiguration_utils.py\u001b[0m:\u001b[94m573\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mget_config_dict\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m570 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m571 \u001b[0m\u001b[2m│   │   \u001b[0moriginal_kwargs = copy.deepcopy(kwargs)                        \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m572 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Get config dict associated with the base config file\u001b[0m         \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m573 \u001b[2m│   │   \u001b[0mconfig_dict, kwargs = \u001b[96mcls\u001b[0m._get_config_dict(pretrained_model_na \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m574 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict:                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m575 \u001b[0m\u001b[2m│   │   │   \u001b[0moriginal_kwargs[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m] = config_dict[\u001b[33m\"\u001b[0m\u001b[33m_commit_has\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m576 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/gpt4all/transformers/src/transformers/\u001b[0m\u001b[1;33mconfiguration_utils.py\u001b[0m:\u001b[94m628\u001b[0m in \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92m_get_config_dict\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m625 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m626 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m627 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Load from local folder or from cache or download fro\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m628 \u001b[2m│   │   │   │   \u001b[0mresolved_config_file = cached_file(                    \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m629 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpretrained_model_name_or_path,                     \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m630 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconfiguration_file,                                \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m631 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcache_dir=cache_dir,                               \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[2;33m/content/gpt4all/transformers/src/transformers/utils/\u001b[0m\u001b[1;33mhub.py\u001b[0m:\u001b[94m424\u001b[0m in           \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[92mcached_file\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 421 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                             \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 422 \u001b[0m\u001b[2m│   \u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 423 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m RepositoryNotFoundError:                                   \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 424 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mEnvironmentError\u001b[0m(                                       \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 425 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mpath_or_repo_id\u001b[33m}\u001b[0m\u001b[33m is not a local folder and is not a va\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 426 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mlisted on \u001b[0m\u001b[33m'\u001b[0m\u001b[33mhttps://huggingface.co/models\u001b[0m\u001b[33m'\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33mIf this is a \u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m│\u001b[0m   \u001b[2m 427 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mpass a token having permission to this repo with `use_au\u001b[0m \u001b[31m│\u001b[0m\n",
            "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
            "\u001b[1;91mOSError: \u001b[0mLlamaForCausalLM is not a local folder and is not a valid model \n",
            "identifier listed on \u001b[32m'https://huggingface.co/models'\u001b[0m\n",
            "If this is a private repository, make sure to pass a token having permission to \n",
            "this repo with `use_auth_token` or log in with `huggingface-cli login` and pass \n",
            "`\u001b[33muse_auth_token\u001b[0m=\u001b[3;92mTrue\u001b[0m`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fnBueJUU7XBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j9nPVfTG6c-Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}